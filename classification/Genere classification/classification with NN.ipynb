{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['track_id', 'bit_rate', 'comments', 'composer', 'date_created',\n",
      "       'date_recorded', 'duration', 'favorites', 'genre_top', 'genres',\n",
      "       'genres_all', 'information', 'interest', 'language_code', 'license',\n",
      "       'listens', 'lyricist', 'number', 'publisher', 'tags', 'title'],\n",
      "      dtype='object')\n",
      "   track_id  acousticness  danceability    energy  instrumentalness  liveness  \\\n",
      "0         2      0.416675      0.675894  0.634476          0.010628  0.177647   \n",
      "1         3      0.374408      0.528643  0.817461          0.001851  0.105880   \n",
      "2         5      0.043567      0.745566  0.701470          0.000697  0.373143   \n",
      "3        10      0.951670      0.658179  0.924525          0.965427  0.115474   \n",
      "4       134      0.452217      0.513238  0.560410          0.019443  0.096567   \n",
      "\n",
      "   speechiness    tempo   valence  \n",
      "0     0.159310  165.922  0.576661  \n",
      "1     0.461818  126.957  0.269240  \n",
      "2     0.124595  100.260  0.621661  \n",
      "3     0.032985  111.562  0.963590  \n",
      "4     0.525519  114.290  0.894072  \n",
      "(4802, 10)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4802 entries, 0 to 4801\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   track_id          4802 non-null   int64  \n",
      " 1   acousticness      4802 non-null   float64\n",
      " 2   danceability      4802 non-null   float64\n",
      " 3   energy            4802 non-null   float64\n",
      " 4   instrumentalness  4802 non-null   float64\n",
      " 5   liveness          4802 non-null   float64\n",
      " 6   speechiness       4802 non-null   float64\n",
      " 7   tempo             4802 non-null   float64\n",
      " 8   valence           4802 non-null   float64\n",
      " 9   genre_top         4802 non-null   object \n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 412.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read in track metadata with genre labels\n",
    "tracks = pd.read_csv(\"./fma-rock-vs-hiphop.csv\")\n",
    "print(tracks.columns)\n",
    "\n",
    "# Read in track metrics with the features\n",
    "echonest_metrics = pd.read_json(\"./echonest-metrics.json\",precise_float=True)\n",
    "print(echonest_metrics.head())\n",
    "\n",
    "# Merge the relevant columns of tracks and echonest_metrics\n",
    "echo_tracks = echonest_metrics.merge(tracks[[\"track_id\",\"genre_top\"]],left_on='track_id', right_on='track_id')\n",
    "\n",
    "# Inspect the resultant dataframe\n",
    "print(echo_tracks.shape)\n",
    "print(echo_tracks.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acousticness  danceability    energy  instrumentalness  liveness  \\\n",
      "0      0.416675      0.675894  0.634476          0.010628  0.177647   \n",
      "1      0.374408      0.528643  0.817461          0.001851  0.105880   \n",
      "2      0.043567      0.745566  0.701470          0.000697  0.373143   \n",
      "3      0.452217      0.513238  0.560410          0.019443  0.096567   \n",
      "4      0.988306      0.255661  0.979774          0.973006  0.121342   \n",
      "\n",
      "   speechiness    tempo   valence  \n",
      "0     0.159310  165.922  0.576661  \n",
      "1     0.461818  126.957  0.269240  \n",
      "2     0.124595  100.260  0.621661  \n",
      "3     0.525519  114.290  0.894072  \n",
      "4     0.051740   90.241  0.034018  \n",
      "\n",
      "0    Hip-Hop\n",
      "1    Hip-Hop\n",
      "2    Hip-Hop\n",
      "3    Hip-Hop\n",
      "4       Rock\n",
      "Name: genre_top, dtype: object\n",
      "[[-0.19121034  1.30442004  0.03831594 ...  0.37303429  1.15397908\n",
      "   0.46228696]\n",
      " [-0.30603598  0.50188641  0.78817624 ...  2.44615517  0.00791367\n",
      "  -0.69081137]\n",
      " [-1.20481276  1.68413943  0.31285194 ...  0.13513049 -0.77731688\n",
      "   0.63107745]\n",
      " ...\n",
      " [-1.29470431  1.17682795  0.13265633 ...  0.85182206 -0.93541008\n",
      "  -0.07941825]\n",
      " [-1.13869115 -0.02253433  0.57117905 ...  1.40951543  1.31301348\n",
      "   0.47513794]\n",
      " [-0.90611434  1.10148973  0.56322452 ...  1.36030881 -1.43669053\n",
      "   0.76217464]]\n"
     ]
    }
   ],
   "source": [
    "# Define our features \n",
    "features = echo_tracks.drop([\"genre_top\",\"track_id\"],axis=1)\n",
    "print(features.head())\n",
    "print()\n",
    "# Define our labels\n",
    "labels = echo_tracks[\"genre_top\"]\n",
    "print(labels.head())\n",
    "\n",
    "# Import the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features and set the values to a new variable\n",
    "scaler = StandardScaler()\n",
    "scaled_train_features = scaler.fit_transform(features)\n",
    "print(scaled_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Split our data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(scaled_train_features,labels,random_state=10)\n",
    "\n",
    "# Train our decision tree\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "# Predict the labels for the test data\n",
    "pred_labels_tree = tree.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.66      0.68      0.67       235\n",
      "        Rock       0.92      0.92      0.92       966\n",
      "\n",
      "    accuracy                           0.87      1201\n",
      "   macro avg       0.79      0.80      0.79      1201\n",
      "weighted avg       0.87      0.87      0.87      1201\n",
      "\n",
      "Logistic Regression: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.80      0.61      0.69       235\n",
      "        Rock       0.91      0.96      0.94       966\n",
      "\n",
      "    accuracy                           0.89      1201\n",
      "   macro avg       0.86      0.79      0.82      1201\n",
      "weighted avg       0.89      0.89      0.89      1201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "# Train our logistic regression and predict labels for the test set\n",
    "logreg = LogisticRegression(random_state=10)\n",
    "logreg.fit(train_features, train_labels)\n",
    "pred_labels_logit = logreg.predict(test_features)\n",
    "\n",
    "# Create the classification report for both models\n",
    "from sklearn.metrics import classification_report\n",
    "class_rep_tree = classification_report(test_labels,pred_labels_tree)\n",
    "class_rep_log = classification_report(test_labels,pred_labels_logit)\n",
    "\n",
    "print(\"Decision Tree: \\n\", class_rep_tree)\n",
    "print(\"Logistic Regression: \\n\", class_rep_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   track_id  acousticness  danceability    energy  instrumentalness  liveness  \\\n",
      "0         2      0.416675      0.675894  0.634476          0.010628  0.177647   \n",
      "1         3      0.374408      0.528643  0.817461          0.001851  0.105880   \n",
      "2         5      0.043567      0.745566  0.701470          0.000697  0.373143   \n",
      "3       134      0.452217      0.513238  0.560410          0.019443  0.096567   \n",
      "4       153      0.988306      0.255661  0.979774          0.973006  0.121342   \n",
      "\n",
      "   speechiness    tempo   valence genre_top  \n",
      "0     0.159310  165.922  0.576661   Hip-Hop  \n",
      "1     0.461818  126.957  0.269240   Hip-Hop  \n",
      "2     0.124595  100.260  0.621661   Hip-Hop  \n",
      "3     0.525519  114.290  0.894072   Hip-Hop  \n",
      "4     0.051740   90.241  0.034018      Rock  \n",
      "(910, 10)\n",
      "(3892, 10)\n",
      "(910, 10)\n",
      "(910, 10)\n"
     ]
    }
   ],
   "source": [
    "# Subset only the hip-hop tracks, and then only the rock tracks\n",
    "print(echo_tracks.head())\n",
    "hop_only = echo_tracks.loc[echo_tracks[\"genre_top\"] == \"Hip-Hop\"]\n",
    "rock_only = echo_tracks.loc[echo_tracks[\"genre_top\"] == \"Rock\"]\n",
    "print(hop_only.shape)\n",
    "print(rock_only.shape)\n",
    "\n",
    "# sample the rocks songs to be the same number as there are hip-hop songs\n",
    "rock_only = rock_only.sample(n=hop_only.shape[0],random_state=10)\n",
    "print(hop_only.shape)\n",
    "print(rock_only.shape)\n",
    "\n",
    "# concatenate the dataframes rock_only and hop_only\n",
    "rock_hop_bal = pd.concat([rock_only,hop_only])\n",
    "\n",
    "# The features, labels, and pca projection are created for the balanced dataframe\n",
    "features = rock_hop_bal.drop(['genre_top', 'track_id'], axis=1) \n",
    "labelss = rock_hop_bal['genre_top']\n",
    "#pcap = pca.fit_transform(scaler.fit_transform(features))\n",
    "\n",
    "# Redefine the train and test set with the pca_projection from the balanced data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features,labelss\n",
    "                                                                            ,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.81      0.85      0.83       230\n",
      "        Rock       0.84      0.79      0.81       225\n",
      "\n",
      "    accuracy                           0.82       455\n",
      "   macro avg       0.82      0.82      0.82       455\n",
      "weighted avg       0.82      0.82      0.82       455\n",
      "\n",
      "Logistic Regression: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.84      0.82      0.83       230\n",
      "        Rock       0.82      0.84      0.83       225\n",
      "\n",
      "    accuracy                           0.83       455\n",
      "   macro avg       0.83      0.83      0.83       455\n",
      "weighted avg       0.83      0.83      0.83       455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shikhar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Train our decision tree on the balanced data\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(train_features, train_labels)\n",
    "pred_labels_tree = tree.predict(test_features)\n",
    "# Train our logistic regression on the balanced data\n",
    "\n",
    "logreg = LogisticRegression(random_state=10)\n",
    "logreg.fit(train_features, train_labels)\n",
    "pred_labels_logit = logreg.predict(test_features)\n",
    "# Compare the models\n",
    "print(\"Decision Tree: \\n\", classification_report(test_labels,pred_labels_tree))\n",
    "print(\"Logistic Regression: \\n\", classification_report(test_labels,pred_labels_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.90      0.83      0.86       230\n",
      "        Rock       0.84      0.90      0.87       225\n",
      "\n",
      "    accuracy                           0.86       455\n",
      "   macro avg       0.87      0.86      0.86       455\n",
      "weighted avg       0.87      0.86      0.86       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel=\"linear\",gamma=\"auto\")\n",
    "svc.fit(train_features, train_labels)\n",
    "pred=svc.predict(test_features)\n",
    "print(\"SVC: \\n\", classification_report(test_labels,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(label):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import numpy as np\n",
    "    Le=LabelEncoder()\n",
    "    y=Le.fit_transform(label) \n",
    "    \n",
    "    Ny=len(np.unique(label))\n",
    "    print(\"unique\",Ny)\n",
    "    print(\"label\",Le)\n",
    "    return y,Ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "unique 2\n",
      "label LabelEncoder()\n"
     ]
    }
   ],
   "source": [
    "print(type(labels))\n",
    "lb,c=create_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(scaled_train_features,lb\n",
    "                                                                            ,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution with neural networks\n",
    "#import libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32,activation=\"relu\",input_dim=8))\n",
    "    model.add(Dense(64,activation=\"relu\"))\n",
    "    Dropout(0.2)\n",
    "    model.add(Dense(64,activation=\"relu\"))\n",
    "    #Dropout(0.2)\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 8) [1 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,625\n",
      "Trainable params: 6,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 0s 138us/step - loss: 0.1653 - accuracy: 0.8000 - val_loss: 0.0745 - val_accuracy: 0.9141\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 0s 48us/step - loss: 0.0814 - accuracy: 0.9074 - val_loss: 0.0604 - val_accuracy: 0.9307\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 0s 47us/step - loss: 0.0718 - accuracy: 0.9105 - val_loss: 0.0552 - val_accuracy: 0.9307\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 0s 49us/step - loss: 0.0677 - accuracy: 0.9182 - val_loss: 0.0511 - val_accuracy: 0.9418\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 0s 48us/step - loss: 0.0635 - accuracy: 0.9185 - val_loss: 0.0528 - val_accuracy: 0.9418\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 0s 49us/step - loss: 0.0633 - accuracy: 0.9204 - val_loss: 0.0559 - val_accuracy: 0.9363\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 0s 49us/step - loss: 0.0621 - accuracy: 0.9219 - val_loss: 0.0503 - val_accuracy: 0.9391\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 0s 46us/step - loss: 0.0602 - accuracy: 0.9250 - val_loss: 0.0529 - val_accuracy: 0.9307\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 0s 50us/step - loss: 0.0584 - accuracy: 0.9244 - val_loss: 0.0529 - val_accuracy: 0.9391\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 0s 50us/step - loss: 0.0573 - accuracy: 0.9222 - val_loss: 0.0496 - val_accuracy: 0.9391\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 0s 50us/step - loss: 0.0545 - accuracy: 0.9284 - val_loss: 0.0480 - val_accuracy: 0.9474\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 0s 69us/step - loss: 0.0551 - accuracy: 0.9296 - val_loss: 0.0486 - val_accuracy: 0.9391\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 0s 62us/step - loss: 0.0538 - accuracy: 0.9318 - val_loss: 0.0545 - val_accuracy: 0.9363\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 0s 58us/step - loss: 0.0524 - accuracy: 0.9318 - val_loss: 0.0501 - val_accuracy: 0.9474\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 0s 68us/step - loss: 0.0505 - accuracy: 0.9327 - val_loss: 0.0504 - val_accuracy: 0.9474\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.93 - 0s 56us/step - loss: 0.0505 - accuracy: 0.9389 - val_loss: 0.0497 - val_accuracy: 0.9446\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 0s 71us/step - loss: 0.0489 - accuracy: 0.9386 - val_loss: 0.0483 - val_accuracy: 0.9501\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 0s 58us/step - loss: 0.0489 - accuracy: 0.9364 - val_loss: 0.0519 - val_accuracy: 0.9391\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 0s 65us/step - loss: 0.0468 - accuracy: 0.9401 - val_loss: 0.0490 - val_accuracy: 0.9474\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 0s 63us/step - loss: 0.0470 - accuracy: 0.9426 - val_loss: 0.0521 - val_accuracy: 0.9474\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 0s 55us/step - loss: 0.0477 - accuracy: 0.9377 - val_loss: 0.0517 - val_accuracy: 0.9391\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 0s 53us/step - loss: 0.0449 - accuracy: 0.9457 - val_loss: 0.0581 - val_accuracy: 0.9335\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 0s 50us/step - loss: 0.0451 - accuracy: 0.9448 - val_loss: 0.0524 - val_accuracy: 0.9474\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 0s 53us/step - loss: 0.0439 - accuracy: 0.9472 - val_loss: 0.0513 - val_accuracy: 0.9474\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 0s 76us/step - loss: 0.0437 - accuracy: 0.9466 - val_loss: 0.0504 - val_accuracy: 0.9474\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 0s 57us/step - loss: 0.0423 - accuracy: 0.9469 - val_loss: 0.0534 - val_accuracy: 0.9446\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 0s 61us/step - loss: 0.0433 - accuracy: 0.9460 - val_loss: 0.0531 - val_accuracy: 0.9446\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 0s 68us/step - loss: 0.0404 - accuracy: 0.9491 - val_loss: 0.0502 - val_accuracy: 0.9474\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 0s 55us/step - loss: 0.0402 - accuracy: 0.9512 - val_loss: 0.0576 - val_accuracy: 0.9418\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 0s 72us/step - loss: 0.0400 - accuracy: 0.9528 - val_loss: 0.0509 - val_accuracy: 0.9501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1967fcb1488>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_features,train_labels,epochs=30,validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
